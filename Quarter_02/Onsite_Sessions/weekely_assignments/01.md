#   Assignment 01: Understanding OpenAI Chat Completion API Parameters
___

## Here are the API Parameters with **Real-Life Examples**


### **1. Messages**

This parameter serves as the conversation's input. It consists of a list of objects, each having a role (system, user, or assistant) and corresponding content.

Purpose: It structures the conversation by providing context for the model to generate coherent and relevant responses based on the provided history.



```python
import openai

response = openai.ChatCompletion.create(
    messages=[
        {"role": "system", "content": "You are an AI expert in health advice."},
        {"role": "user", "content": "How can I manage a migraine effectively?"}
    ]
)
```

---

### **2. Modle**

Specifies which language model you want to use, such as gpt-3.5-turbo or gpt-4.

Purpose: It determines the capabilities, accuracy, and cost of the response generation process.


```python
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "user", "content": "Summarize the benefits of regular exercise."}
    ]
)

```

---

### **3. Max Completion Tokens**

Limits the number of tokens (words/characters) the model can use in its response.

Purpose: It helps control the length of the response and ensures cost-efficiency since the API's pricing depends on token usage.


```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "Explain the concept of blockchain in simple terms."}
    ],
    max_tokens=50  # Limits the explanation to approximately 50 tokens.
)

```

---

### **4. n**

Determines the number of response completions to generate for each input.

Purpose: Useful for comparing multiple responses and selecting the most appropriate one.

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "What are some effective study techniques?"}
    ],
    n=3  # Generate 3 different responses.
)

for i, choice in enumerate(response['choices']):
    print(f"Response {i+1}: {choice['message']['content']}")
```

---

### **5. Stream**

If set to true, responses are sent back incrementally as a stream of tokens, rather than waiting for the entire response.

Purpose: Improves user experience by displaying parts of the response in real time, especially for long outputs.

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "Describe the process of photosynthesis."}
    ],
    stream=True  # Streams the response token by token.
)

for chunk in response:
    print(chunk['choices'][0]['delta'].get('content', ''), end='')
```

---

### **6. Temperature**


Controls the randomness of the output by adjusting the probability distribution of token selection.

Purpose:

Lower values (e.g., 0.2) produce more deterministic, focused responses.

Higher values (e.g., 0.8) introduce more creativity and randomness.

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "Suggest some creative ideas for a birthday party."}
    ],
    temperature=0.8  # Encourages more creative ideas.
)

print(response['choices'][0]['message']['content'])
```

---

### **7. Top_p**

An alternative to temperature, this parameter uses nucleus sampling to limit the token selection to a subset that adds up to a specified probability (e.g., 0.9).

Purpose: Offers a more focused control over randomness by considering only the top tokens that contribute significantly to the response.

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "What is the future of renewable energy?"}
    ],
    top_p=0.9  # Limits the response to the most relevant subset of tokens.
)
```

---

### **8. Tools**

A parameter that allows the model to interact with external tools or plugins for specialized tasks (e.g., browsing, code execution, or database queries).

Purpose: Extends the model's capabilities beyond text generation, enabling it to perform tasks like calculations, API calls, or fetching real-time data.

```python
# Example: Calculating a math expression using a tool (hypothetical code).
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You can calculate math problems using a calculator plugin."},
        {"role": "user", "content": "What is 25 * 37?"}
    ],
    functions=[
        {
            "name": "calculate",
            "description": "Performs basic arithmetic operations.",
            "parameters": {"expression": "string"}
        }
    ]
)

print(response['choices'][0]['message']['content'])
```
---
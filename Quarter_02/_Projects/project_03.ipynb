{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYdKHxhSftZj"
      },
      "source": [
        "# **Project 02: LangChain RAG Project**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **Task:**\n",
        "\n",
        "Create a Google Colab Notebook that integrates a function/tool-calling workflow using LangChain, Google Gemini Flash, and custom tools. Your system should:\n",
        "\n",
        "- **Set Up Environment Variables:** Load the Google Gemini Flash API key securely.\n",
        "- **Define the Custom Tool:** Implement a set of tools to perform some custom actions.\n",
        "- **Create the Tool Wrapper for LangChain:** Integrate the calculator with LangChain as a callable tool.\n",
        "- **Set Up the Google Gemini Flash Model:** Initialize the Gemini model with tool-calling capabilities.\n",
        "- **Build the Conversational Chain:** Develop a conversational interface that maintains context and interacts with the tools.\n",
        "- **Test the Custom Tools:** Demonstrate the system's ability to handle various queries.\n",
        "- **Optional Enhancements:** Extend functionality with advanced operations, improved error handling, UI integration, or logging."
      ],
      "metadata": {
        "id": "b2Y_i7Z3ge6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU  langchain-google-genai"
      ],
      "metadata": {
        "id": "kIpB0AhkGipH"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "YwP5dQKoHPMz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    A simple calculator tool that evaluates mathematical expressions.\n",
        "    Args:\n",
        "        expression (str): A mathematical expression to evaluate.\n",
        "    Returns:\n",
        "        str: The result of the evaluation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating expression: {e}\"\n",
        "\n",
        "@tool\n",
        "def acceleration(velocity: int, time: int) -> float:\n",
        "    \"\"\"Find acceleration\"\"\"\n",
        "    return velocity / time\n",
        "\n"
      ],
      "metadata": {
        "id": "_GnX3sAbgJDX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tool\n",
        "tools = [calculator, acceleration]"
      ],
      "metadata": {
        "id": "b45QO0XnpH3c"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize the Gemini model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\"\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "d6KFe-0kpa2v"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
        "\n",
        "messages = [HumanMessage(query)]\n",
        "\n",
        "ai_msg = llm_with_tools.invoke(messages)\n",
        "\n",
        "print(ai_msg.tool_calls)\n",
        "\n",
        "messages.append(ai_msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCEbI6EJq9zS",
        "outputId": "0b5c163d-78c0-4101-aae5-2a3f96328d30"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'calculator', 'args': {'expression': '3 * 12'}, 'id': '8e753e63-a971-4d8a-8b6d-5b6f7d35e62b', 'type': 'tool_call'}, {'name': 'calculator', 'args': {'expression': '11 + 49'}, 'id': 'b02c7313-4d81-4a91-9c2d-c8e0d97e5705', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tool_call in ai_msg.tool_calls:\n",
        "    selected_tool = {\"calculator\": calculator, \"acceleration\": acceleration}[tool_call[\"name\"].lower()]\n",
        "    tool_msg = selected_tool.invoke(tool_call)\n",
        "    messages.append(tool_msg)\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mItbMAt_rfUB",
        "outputId": "3f39fab1-24a8-483d-dbe8-c0b365143cc7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"11 + 49\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8704166e-b6f9-4915-92c0-40b6f60efd47-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '3 * 12'}, 'id': '8e753e63-a971-4d8a-8b6d-5b6f7d35e62b', 'type': 'tool_call'}, {'name': 'calculator', 'args': {'expression': '11 + 49'}, 'id': 'b02c7313-4d81-4a91-9c2d-c8e0d97e5705', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 15, 'total_tokens': 147, 'input_token_details': {'cache_read': 0}}),\n",
              " ToolMessage(content='36', name='calculator', tool_call_id='8e753e63-a971-4d8a-8b6d-5b6f7d35e62b'),\n",
              " ToolMessage(content='60', name='calculator', tool_call_id='b02c7313-4d81-4a91-9c2d-c8e0d97e5705')]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the llm\n",
        "response = llm_with_tools.invoke(messages)"
      ],
      "metadata": {
        "id": "M32CEVKK3sJq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.content)"
      ],
      "metadata": {
        "id": "ggC-UBa-3aF3",
        "outputId": "423076c6-e037-46e0-a4c9-8e69e92aebd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "3 * 12 is 36, and 11 + 49 is 60."
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}